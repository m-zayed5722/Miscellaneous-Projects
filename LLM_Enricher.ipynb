{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzwCjbQob8dBgr2JLuDeP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-zayed5722/Miscellaneous-Projects/blob/main/LLM_Enricher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqdl_E0ttZVF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import time\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "from dataclasses import dataclass\n",
        "import logging\n",
        "from src.schema import MenuItem, MenuSchema\n",
        "from pydantic import ValidationError\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LLMConfig:\n",
        "    \"\"\"Configuration for LLM integration\"\"\"\n",
        "    model_name: str = \"llama2\"  # Default Ollama model\n",
        "    base_url: str = \"http://localhost:11434\"\n",
        "    timeout: int = 600  # 10 minutes timeout for large models\n",
        "    max_retries: int = 3\n",
        "    temperature: float = 0.1  # Low temperature for consistent structured output\n",
        "\n",
        "\n",
        "class OllamaClient:\n",
        "    \"\"\"Client for interacting with Ollama API\"\"\"\n",
        "\n",
        "    def __init__(self, config: LLMConfig = None):\n",
        "        self.config = config or LLMConfig()\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def is_available(self) -> bool:\n",
        "        \"\"\"Check if Ollama server is available\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.config.base_url}/api/tags\", timeout=5)\n",
        "            return response.status_code == 200\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Ollama not available: {e}\")\n",
        "            return False\n",
        "\n",
        "    def list_models(self) -> List[str]:\n",
        "        \"\"\"List available models\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.config.base_url}/api/tags\", timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                return [model['name'] for model in data.get('models', [])]\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error listing models: {e}\")\n",
        "        return []\n",
        "\n",
        "    def generate(self, prompt: str, model: str = None) -> Optional[str]:\n",
        "        \"\"\"Generate text using Ollama\"\"\"\n",
        "        model = model or self.config.model_name\n",
        "\n",
        "        payload = {\n",
        "            \"model\": model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"temperature\": self.config.temperature\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for attempt in range(self.config.max_retries):\n",
        "            try:\n",
        "                self.logger.info(f\"Sending request to {model} (timeout: {self.config.timeout}s)...\")\n",
        "                start_time = time.time()\n",
        "\n",
        "                response = requests.post(\n",
        "                    f\"{self.config.base_url}/api/generate\",\n",
        "                    json=payload,\n",
        "                    timeout=self.config.timeout\n",
        "                )\n",
        "\n",
        "                elapsed_time = time.time() - start_time\n",
        "                self.logger.info(f\"Response received in {elapsed_time:.2f} seconds\")\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    return result.get('response', '').strip()\n",
        "                else:\n",
        "                    self.logger.warning(f\"Ollama API error: {response.status_code} - {response.text}\")\n",
        "\n",
        "            except requests.exceptions.Timeout as e:\n",
        "                self.logger.warning(f\"Attempt {attempt + 1} timed out after {self.config.timeout}s: {e}\")\n",
        "                if attempt < self.config.max_retries - 1:\n",
        "                    self.logger.info(\"Retrying with exponential backoff...\")\n",
        "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "                if attempt < self.config.max_retries - 1:\n",
        "                    time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "class LLMEnricher:\n",
        "    \"\"\"LLM-based menu item enricher\"\"\"\n",
        "\n",
        "    def __init__(self, config: LLMConfig = None):\n",
        "        self.config = config or LLMConfig()\n",
        "        self.client = OllamaClient(config)\n",
        "        self.schema = MenuSchema()\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # System prompt template\n",
        "        self.system_prompt = \"\"\"You are an expert food categorization assistant. Your task is to analyze menu item names and return structured, clean information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wgi9rn19yiBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('.')\n",
        "from src.llm_enricher import get_enricher, LLMConfig\n",
        "from src.baseline import BaselineClassifier\n",
        "import json\n",
        "\n",
        "def test_noodles_enrichment():\n",
        "    \"\"\"Test menu item enrichment specifically for noodles\"\"\"\n",
        "\n",
        "    print(\"🍜 Testing Menu Item Enrichment for Noodles\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Configure to use real Ollama (not mock)\n",
        "    config = LLMConfig(model_name=\"llama2\", timeout=60)\n",
        "    llm_enricher = get_enricher(config=config, use_mock=False)\n",
        "    baseline = BaselineClassifier()\n",
        "\n",
        "    # Test the specific example \"noodles\"\n",
        "    test_item = \"noodles\"\n",
        "\n",
        "    print(f\"📝 Testing item: '{test_item}'\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Test LLM enrichment\n",
        "    print(\"🤖 LLM (Ollama) Result:\")\n",
        "    try:\n",
        "        llm_result = llm_enricher.enrich_item(test_item)\n",
        "        if llm_result:\n",
        "            print(f\"   ✅ Name: {llm_result.item_name}\")\n",
        "            print(f\"   ✅ Category: {llm_result.category}\")\n",
        "            print(f\"   ✅ Cuisine: {llm_result.cuisine}\")\n",
        "            print(f\"   ✅ Attributes: {llm_result.attributes if llm_result.attributes else 'None'}\")\n",
        "        else:\n",
        "            print(\"   ❌ LLM enrichment failed\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Error: {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    # Test baseline for comparison\n",
        "    print(\"📝 Baseline (Rule-based) Result:\")\n",
        "    try:\n",
        "        baseline_result = baseline.classify_item(test_item)\n",
        "        print(f\"   ✅ Name: {baseline_result.item_name}\")\n",
        "        print(f\"   ✅ Category: {baseline_result.category}\")\n",
        "        print(f\"   ✅ Cuisine: {baseline_result.cuisine}\")\n",
        "        print(f\"   ✅ Attributes: {baseline_result.attributes if baseline_result.attributes else 'None'}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Error: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"✅ Test completed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_noodles_enrichment()"
      ],
      "metadata": {
        "id": "2yEDz4q5yiEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from src.baseline_order_parser import BaselineOrderParser\n",
        "\n",
        "def debug_double_bacon_matching():\n",
        "    print(\"🔍 Debugging Double Bacon Quarter Pounder Matching\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    parser = BaselineOrderParser()\n",
        "\n",
        "    # Find the Double Bacon Quarter Pounder item\n",
        "    double_bacon_item = None\n",
        "    for item in parser.menu_items:\n",
        "        if \"Double Bacon Quarter Pounder\" in item.name:\n",
        "            double_bacon_item = item\n",
        "            break\n",
        "\n",
        "    # Find ALL Quarter Pounder items and check them\n",
        "    quarter_pounder_items = []\n",
        "    for item in parser.menu_items:\n",
        "        if \"quarter pounder\" in item.name.lower():\n",
        "            quarter_pounder_items.append(item)\n",
        "\n",
        "    test_text = \"craving a mcchicken with large fries and medium sprite, mayo and ketchup included\"\n",
        "    print(f\"Testing against: '{test_text}'\")\n",
        "    print(f\"Found {len(quarter_pounder_items)} Quarter Pounder items:\\n\")\n",
        "\n",
        "    for item in quarter_pounder_items:\n",
        "        print(f\"Item: {item.name}\")\n",
        "        print(f\"Keywords: {item.keywords}\")\n",
        "\n",
        "        matched_keywords = []\n",
        "        for keyword in item.keywords:\n",
        "            if keyword in test_text.lower():\n",
        "                matched_keywords.append(keyword)\n",
        "\n",
        "        if matched_keywords:\n",
        "            print(f\"❌ Matched keywords: {matched_keywords}\")\n",
        "        else:\n",
        "            print(\"✅ No keywords matched!\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    debug_double_bacon_matching()"
      ],
      "metadata": {
        "id": "NlDZGjPkG33V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtBq1eGAyiIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDRP75layiK_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}